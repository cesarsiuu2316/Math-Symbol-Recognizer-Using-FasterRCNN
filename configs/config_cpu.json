{
    "paths": {
        "config_path": "configs/config_cpu.json",
        "crohme_dir": "TC11_CROHME23",
        "train_image_dir": "TC11_CROHME23/IMG/train/OffHME",
        "train_lg_dir": "TC11_CROHME23/SymLG/train/OffHME",
        "data_dir": "data",
        "class_mapping_path": "data/class_mapping.json",
        "train_annotations_path": "data/train_annotations.json",
        "calibrated_whiteboard_bboxes_path": "data/calibrated_whiteboard_bboxes.json",
        "whiteboard_dir": "whiteboard_data",
        "output_dir": "output",
        "model_checkpoint_prefix": "output/fasterrcnn_resnet50_fpn.chkpt_optim_",
        "final_model_path": "output/fasterrcnn_resnet50_fpn_final_model.dat"
    },
    "model_params": {
        "_architecture": "fasterrcnn_resnet50_fpn",
        "weights": null,
        "weights_backbone": "IMAGENET1K_V1",
        "trainable_backbone_layers": 5,
        "_comment_layers": "5 means unfreeze all layers for full retraining (required for domain shift)",
        "_get_new_anchor_params_use_comment": "1: use saved data / 2: continue where left off / 3: restart",
        "get_new_anchor_params": 2,
        "anchor_params": {
            "_Comment": "original first size was 9, switched to 10 to match min feature map size of 320/32=10",
            "sizes": [
                12,
                25,
                50,
                100
            ],
            "aspect_ratios": [
                0.2,
                0.5,
                1.0,
                2.0,
                5.0
            ]
        },
        "roi_heads": {
            "_comment_box_detections_per_img": "Estimar maxima cantidad de simbolos por imagen en pizarra blanca",
            "box_detections_per_img": 100,
            "box_nms_thresh": 0.5,
            "box_score_thresh": 0.05,
            "_comment_nms": "IoU threshold: Boxes overlapping more than 0.5 will be suppressed.",
            "_comment_score": "Score threshold: Boxes with a score lower than 0.05 will be removed."
        }
    },
    "training_params": {
        "device": "cpu",
        "batch_size": 2,
        "num_epochs": 1,
        "learning_rate": 0.0001,
        "weight_decay": 0.05,
        "optimizer": "AdamW",
        "grad_clip_max_norm": 10.0,
        "lr_scheduler": {
            "type": "StepLR",
            "step_size": 3,
            "gamma": 0.1
        },
        "num_workers": 2,
        "print_freq": 15
    },
    "transform_params": {
        "target_min_size": 320,
        "scaling_factor": 0.40833864588156277,
        "transform": true,
        "augmentation_params": {
            "_comment": "Values tuned for small ~19px median symbols",
            "morphological_kernels": [2,3],
            "blur_kernels": [3,5],
            "noise_sigma_range": [20,50],
            "threshold_range": [100,150]
        }
    }
}